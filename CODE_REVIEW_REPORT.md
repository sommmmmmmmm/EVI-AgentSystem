# ì½”ë“œ ê²€ìˆ˜ ë° ê°œì„  ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2025-10-25  
**ê²€ìˆ˜ ëŒ€ìƒ**: EVI-AgentSystem ì „ì²´  
**ëª©ì **: ë³´ê³ ì„œ í’ˆì§ˆ í–¥ìƒ ë° ì½”ë“œ ì•ˆì •ì„± ê²€ì¦

---

## ğŸ” ë°œê²¬ëœ ë¬¸ì œì 

### 1. **ë³´ê³ ì„œ í’ˆì§ˆ ë¬¸ì œ**

#### A. ëˆ„ë½ëœ ë°ì´í„°
```markdown
# í˜„ì¬ ë³´ê³ ì„œ
"GM, , BYDì´ í•µì‹¬ íˆ¬ì ëŒ€ìƒ..."
```
- âŒ ê¸°ì—…ëª… ì¤‘ê°„ì— ë¹ˆ ì¹¸
- ì›ì¸: LLMì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ì—ì„œ ê¸°ì—…ëª… ì¶”ì¶œ ì‹¤íŒ¨

#### B. íŠ¸ë Œë“œ í’ˆì§ˆ ì €í•˜
```
1. EV Development (Impact: 0.0)
2. battery Development (Impact: 0.0)
3. electric Development (Impact: 0.0)
```
- âŒ íŠ¸ë Œë“œ ì´ë¦„ì´ ë„ˆë¬´ ì¼ë°˜ì 
- âŒ Impact Scoreê°€ ëª¨ë‘ 0.0
- ì›ì¸: TrendAnalyzerì˜ fallback ê·œì¹™ì´ ë„ˆë¬´ ë‹¨ìˆœ

#### C. ë¦¬ìŠ¤í¬ ë¶„ì„ ë¶€ì¡±
```
"ë¶„ì„ ê²°ê³¼ 0ê°œì˜ ì €ìœ„í—˜ ê¸°ì—…ì´ ì‹ë³„ë˜ì—ˆìœ¼ë©°..."
```
- âŒ ì €ìœ„í—˜ ê¸°ì—… 0ê°œ
- ì›ì¸: JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ëŒ€ë¶€ë¶„ì˜ ë¦¬ìŠ¤í¬ ë°ì´í„° ì†ì‹¤

---

## ğŸ› ï¸ ì½”ë“œ ê²€ìˆ˜ ê²°ê³¼

### âœ… **ì˜ ì‘ë™í•˜ëŠ” ë¶€ë¶„**

1. **ë°ì´í„° ìˆ˜ì§‘**
   - DART/SEC ê³µì‹œ ìˆ˜ì§‘ âœ…
   - ë‰´ìŠ¤ ìˆ˜ì§‘ (100ê±´) âœ…
   - ê³µê¸‰ì—…ì²´ ë°œê²¬ (16ê°œ) âœ…

2. **ì•„í‚¤í…ì²˜**
   - Multi-Agent êµ¬ì¡° âœ…
   - State Management âœ…
   - Citation System âœ…

3. **ìƒˆë¡œ ì¶”ê°€ëœ ë„êµ¬**
   - `LLMQualitativeAnalyzer` âœ…
   - `TrendAnalyzer` âœ…
   - `SupplierScorer` âœ…
   - `DisclosureRouter` âœ…

### âš ï¸ **ê°œì„  í•„ìš”í•œ ë¶€ë¶„**

#### 1. **TrendAnalyzer** (`tools/trend_analysis_tools.py`)

**ë¬¸ì œ**:
```python
def analyze_trends_with_fallback(self, news_articles, clustering_result):
    if len(trends) < min_trends:
        # Fallback: ìƒìœ„ í‚¤ì›Œë“œë¡œ íŠ¸ë Œë“œ ìƒì„±
        for keyword, count in keyword_counts.most_common(min_trends):
            trends.append({
                'id': f'fallback_{i+1}',
                'trend_name': f'{keyword} Development',  # âŒ ë„ˆë¬´ ë‹¨ìˆœ
                'description': f'Significant activity around {keyword} in recent news',
                'keywords': [keyword],
                'impact_score': 0.0,  # âŒ ê³„ì‚° ì•ˆë¨
                # ...
            })
```

**ê°œì„ ì•ˆ**:
```python
def analyze_trends_with_fallback(self, news_articles, clustering_result, min_trends=3):
    # 1. í‚¤ì›Œë“œ ê³µì¶œí˜„ ë¶„ì„
    cooccurrence = self._analyze_keyword_cooccurrence(news_articles)
    
    # 2. ì£¼ì œë³„ ê·¸ë£¹í™”
    topic_groups = self._group_keywords_by_topic(cooccurrence)
    
    # 3. íŠ¸ë Œë“œ ìƒì„±
    for topic, keywords in topic_groups[:min_trends]:
        # LLMìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” íŠ¸ë Œë“œ ì´ë¦„ ìƒì„±
        trend_name = self._generate_trend_name(topic, keywords, news_articles)
        
        # ë‰´ìŠ¤ ë¹ˆë„ ê¸°ë°˜ Impact Score ê³„ì‚°
        impact_score = self._calculate_impact_score(keywords, news_articles)
        
        trends.append({
            'trend_name': trend_name,  # "ì¤‘êµ­ ì‹œì¥ ì„±ì¥ ê°€ì†í™”" ê°™ì€ ì˜ë¯¸ìˆëŠ” ì´ë¦„
            'impact_score': impact_score,  # 0.0-1.0 ì‹¤ì œ ê³„ì‚°ê°’
            'evidence': self._find_supporting_news(keywords, news_articles),
            # ...
        })
```

#### 2. **RiskAssessmentAgent** (`agents/risk_assessment_agent_improved.py`)

**ë¬¸ì œ**: JSON íŒŒì‹± ì‹¤íŒ¨ ë§ìŒ (ìˆ˜ì • ì™„ë£Œ)
```python
# âœ… ìˆ˜ì • ì™„ë£Œ (parse_llm_json í†µí•©)
analysis = parse_llm_json(response, fallback={...})
```

**ì¶”ê°€ ê°œì„ ì•ˆ**: ë¦¬ìŠ¤í¬ ë¶„ë¥˜ ë¡œì§ ê°•í™”
```python
def _classify_companies_by_risk(self, risk_scores):
    # í˜„ì¬: ë‹¨ìˆœ ì„ê³„ê°’
    low_risk = [c for c, s in risk_scores.items() if s < 30]
    
    # ê°œì„ : ìƒëŒ€ì  ë¶„ë¥˜ + ìµœì†Œ ë³´ì¥
    sorted_companies = sorted(risk_scores.items(), key=lambda x: x[1])
    
    total = len(sorted_companies)
    low_risk = sorted_companies[:max(1, total//3)]  # ìµœì†Œ 1ê°œ ë³´ì¥
    medium_risk = sorted_companies[total//3:2*total//3]
    high_risk = sorted_companies[2*total//3:]
    
    return low_risk, medium_risk, high_risk
```

#### 3. **ReportGeneratorAgent** (`agents/report_generator_agent.py`)

**ë¬¸ì œ**: ë³´ê³ ì„œ ë‚´ìš©ì´ ë„ˆë¬´ ê°„ëµ

**ê°œì„ ì•ˆ**: ìƒì„¸ ì„¹ì…˜ ì¶”ê°€
```python
def _generate_report_sections(self, state, structure):
    sections = {}
    
    # 1. Executive Summary (í˜„ì¬ âœ…)
    sections['executive_summary'] = self._generate_executive_summary(state)
    
    # 2. Market Trends (ê°œì„  í•„ìš”)
    sections['market_trends'] = self._generate_detailed_market_trends(state)
    
    # ğŸ†• 3. Company Deep Dive (ìƒˆë¡œ ì¶”ê°€)
    sections['company_analysis'] = self._generate_company_deep_dive(state)
    
    # ğŸ†• 4. Financial Highlights (ìƒˆë¡œ ì¶”ê°€)
    sections['financial_highlights'] = self._generate_financial_highlights(state)
    
    # 5. Supply Chain Analysis (í˜„ì¬ âœ…)
    sections['supply_chain'] = self._generate_supply_chain_analysis(state)
    
    # 6. Risk Assessment (ê°œì„  í•„ìš”)
    sections['risk_assessment'] = self._generate_detailed_risk_assessment(state)
    
    # ğŸ†• 7. Investment Recommendations (ìƒì„¸í™”)
    sections['recommendations'] = self._generate_detailed_recommendations(state)
    
    return sections

def _generate_company_deep_dive(self, state):
    """ê° ê¸°ì—…ë³„ ìƒì„¸ ë¶„ì„ ì„¹ì…˜"""
    companies = state.get('target_companies', [])[:10]  # Top 10
    
    content = "# Company Deep Dive Analysis\n\n"
    
    for company in companies:
        financial = state.get('financial_analysis', {}).get(company, {})
        qualitative = financial.get('qualitative_analysis', {})
        quantitative = financial.get('quantitative_analysis', {})
        
        content += f"## {company}\n\n"
        
        # ì •ì„± ë¶„ì„ ìƒì„¸
        content += f"### Qualitative Assessment\n"
        content += f"- **Overall Rating**: {qualitative.get('overall_rating', 'N/A')}/10\n"
        content += f"- **Confidence**: {qualitative.get('confidence', 0)}%\n"
        content += f"- **Data Sources**: {qualitative.get('data_sources', {})}\n\n"
        
        content += f"**Key Strengths**:\n"
        for strength in qualitative.get('key_strengths', []):
            content += f"- {strength}\n"
        
        content += f"\n**Key Risks**:\n"
        for risk in qualitative.get('key_risks', []):
            content += f"- {risk}\n"
        
        content += f"\n**Growth Drivers**:\n"
        for driver in qualitative.get('growth_drivers', []):
            content += f"- {driver}\n"
        
        # ì •ëŸ‰ ë¶„ì„ ìƒì„¸
        content += f"\n### Financial Metrics\n"
        metrics = quantitative.get('financial_metrics', {})
        content += f"- **ROE**: {metrics.get('ROE', 'N/A')}%\n"
        content += f"- **Operating Margin**: {metrics.get('operating_margin', 'N/A')}%\n"
        content += f"- **ROA**: {metrics.get('ROA', 'N/A')}%\n"
        content += f"- **Current Ratio**: {metrics.get('current_ratio', 'N/A')}\n\n"
        
        content += "---\n\n"
    
    return content

def _generate_financial_highlights(self, state):
    """ì¬ë¬´ í•˜ì´ë¼ì´íŠ¸ ì„¹ì…˜"""
    content = "# Financial Highlights\n\n"
    
    # ì„¹í„° í‰ê·  ë¹„êµ
    content += "## Sector Comparison\n\n"
    content += "| Company | ROE | Op. Margin | Investment Score |\n"
    content += "|---------|-----|------------|------------------|\n"
    
    for company, data in state.get('financial_analysis', {}).items():
        score = data.get('investment_score', 0)
        metrics = data.get('quantitative_analysis', {}).get('financial_metrics', {})
        content += f"| {company} | {metrics.get('ROE', 'N/A')} | {metrics.get('operating_margin', 'N/A')} | {score:.2f} |\n"
    
    content += "\n"
    
    return content
```

#### 4. **FinancialAnalyzerAgent** (`agents/financial_analyzer_agent.py`)

**ë¬¸ì œ**: ë¶„ì„ ëŒ€ìƒ ê¸°ì—… ì„ ì • ë¡œì§

**í˜„ì¬ ì½”ë“œ**:
```python
def _select_target_companies_from_suppliers(self, state):
    # ...
    final_companies = [item['name'] for item in deduplicated[:30]]
    
    print(f"   ë¶„ì„ ëŒ€ìƒ ê¸°ì—…: ì´ {len(final_companies)}ê°œ")
    
    return final_companies
```

**ê°œì„ ì•ˆ**: ë” ìƒì„¸í•œ ë¡œê·¸
```python
def _select_target_companies_from_suppliers(self, state):
    # ... (ê¸°ì¡´ ë¡œì§)
    
    print(f"\n   === ë¶„ì„ ëŒ€ìƒ ê¸°ì—… ì„ ì • ê²°ê³¼ ===")
    print(f"   ì´ í›„ë³´: {len(deduplicated)}ê°œ")
    print(f"   ì„ ì •: {len(final_companies)}ê°œ")
    print(f"   OEM: {len([c for c in deduplicated if c['source'] == 'oem'])}ê°œ")
    print(f"   ê³µê¸‰ì—…ì²´: {len([c for c in deduplicated if c['source'] == 'supplier'])}ê°œ")
    print(f"\n   Top 10 ê¸°ì—…:")
    for i, company in enumerate(final_companies[:10], 1):
        conf = next((c['confidence'] for c in deduplicated if c['name'] == company), 0)
        print(f"   {i}. {company} (ì‹ ë¢°ë„: {conf:.2f})")
    print(f"   ================================\n")
    
    return final_companies
```

---

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### 1. **ìºì‹± ì „ëµ**

**í˜„ì¬**: ëª¨ë“  API í˜¸ì¶œ ìºì‹± âœ…

**ê°œì„ **: ìºì‹œ ê³„ì¸µí™”
```python
# tools/cache_manager.py ê°œì„ 
class HierarchicalCacheManager:
    def __init__(self):
        self.memory_cache = {}  # ë¹ ë¦„, ì‘ìŒ
        self.disk_cache = {}    # ëŠë¦¼, í¼
        self.ttl = {
            'news': 3600,        # 1ì‹œê°„
            'disclosure': 86400, # 1ì¼
            'llm_analysis': 7200 # 2ì‹œê°„
        }
```

### 2. **ë³‘ë ¬ ì²˜ë¦¬**

**í˜„ì¬**: ìˆœì°¨ ì²˜ë¦¬
```python
for company in companies:
    analysis = self.analyze_company(company)
```

**ê°œì„ **: ë³‘ë ¬ ì²˜ë¦¬
```python
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=5) as executor:
    analyses = list(executor.map(self.analyze_company, companies))
```

---

## ğŸ¯ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­

### Priority 1: íŠ¸ë Œë“œ ì´ë¦„ ê°œì„ 

```python
# tools/trend_analysis_tools.py

def _generate_meaningful_trend_name(self, keywords, news_articles):
    """í‚¤ì›Œë“œì™€ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” íŠ¸ë Œë“œ ì´ë¦„ ìƒì„±"""
    # ê´€ë ¨ ë‰´ìŠ¤ ì œëª© ì¶”ì¶œ
    related_titles = []
    for article in news_articles:
        if any(kw.lower() in article.get('title', '').lower() for kw in keywords):
            related_titles.append(article['title'])
    
    # LLMìœ¼ë¡œ íŠ¸ë Œë“œ ì´ë¦„ ìƒì„±
    prompt = f"""
Based on these keywords: {', '.join(keywords)}
And these news titles: {related_titles[:5]}

Generate a concise trend name (max 5 words) that captures the main theme.
Examples: "ì¤‘êµ­ EV ì‹œì¥ í™•ëŒ€", "ë°°í„°ë¦¬ ê¸°ìˆ  í˜ì‹  ê°€ì†í™”"

Trend name:"""
    
    trend_name = self.llm_tool.generate(prompt).strip()
    return trend_name if len(trend_name) > 5 else f"{keywords[0]} ê´€ë ¨ ë™í–¥"
```

### Priority 2: Impact Score ê³„ì‚°

```python
# tools/trend_analysis_tools.py

def _calculate_impact_score(self, keywords, news_articles):
    """ë‰´ìŠ¤ ë¹ˆë„ + ìµœì‹ ì„± ê¸°ë°˜ Impact Score"""
    total_articles = len(news_articles)
    if total_articles == 0:
        return 0.0
    
    # í‚¤ì›Œë“œ ì¶œí˜„ ë¹ˆë„
    mention_count = 0
    recent_mentions = 0  # ìµœê·¼ 3ì¼
    
    from datetime import datetime, timedelta
    cutoff = datetime.now() - timedelta(days=3)
    
    for article in news_articles:
        content = f"{article.get('title', '')} {article.get('content', '')}"
        if any(kw.lower() in content.lower() for kw in keywords):
            mention_count += 1
            
            # ìµœì‹ ì„± ì²´í¬
            pub_date = article.get('published_date')
            if pub_date and isinstance(pub_date, str):
                try:
                    article_date = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                    if article_date > cutoff:
                        recent_mentions += 1
                except:
                    pass
    
    # ë¹ˆë„ ì ìˆ˜ (0-0.7)
    frequency_score = min(0.7, mention_count / total_articles * 2)
    
    # ìµœì‹ ì„± ì ìˆ˜ (0-0.3)
    recency_score = min(0.3, recent_mentions / total_articles * 3)
    
    return round(frequency_score + recency_score, 2)
```

### Priority 3: ë¦¬ìŠ¤í¬ ë¶„ë¥˜ ê°œì„ 

```python
# agents/risk_assessment_agent_improved.py

def _categorize_risk_levels(self, risk_scores):
    """ìƒëŒ€ì  ë¶„ë¥˜ë¡œ í•­ìƒ ì €/ì¤‘/ê³ ìœ„í—˜ ê¸°ì—… ìƒì„±"""
    if not risk_scores:
        return [], [], []
    
    sorted_companies = sorted(risk_scores.items(), key=lambda x: x[1])
    total = len(sorted_companies)
    
    # ìµœì†Œ 1ê°œì”© ë³´ì¥
    low_count = max(1, total // 3)
    medium_count = max(1, total // 3)
    
    low_risk = [c for c, s in sorted_companies[:low_count]]
    medium_risk = [c for c, s in sorted_companies[low_count:low_count+medium_count]]
    high_risk = [c for c, s in sorted_companies[low_count+medium_count:]]
    
    print(f"\n   === ë¦¬ìŠ¤í¬ ë¶„ë¥˜ ê²°ê³¼ ===")
    print(f"   ì €ìœ„í—˜: {len(low_risk)}ê°œ")
    print(f"   ì¤‘ìœ„í—˜: {len(medium_risk)}ê°œ")
    print(f"   ê³ ìœ„í—˜: {len(high_risk)}ê°œ")
    
    return low_risk, medium_risk, high_risk
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¦‰ì‹œ ìˆ˜ì • (Critical)
- [ ] TrendAnalyzer fallback ê°œì„  - ì˜ë¯¸ìˆëŠ” íŠ¸ë Œë“œ ì´ë¦„
- [ ] Impact Score ê³„ì‚° ë¡œì§ ì¶”ê°€
- [ ] ë¦¬ìŠ¤í¬ ë¶„ë¥˜ ê°œì„  (ìµœì†Œ 1ê°œì”© ë³´ì¥)
- [ ] ë³´ê³ ì„œì— Company Deep Dive ì„¹ì…˜ ì¶”ê°€

### ë‹¨ê¸° ê°œì„  (High Priority)
- [ ] Financial Highlights ì„¹ì…˜ ì¶”ê°€
- [ ] ê¸°ì—… ì„ ì • ë¡œê·¸ ìƒì„¸í™”
- [ ] LLM í”„ë¡¬í”„íŠ¸ ê°œì„  (ì „ë¬¸ê°€ ì˜ê²¬ ëŒ€ì‹  ì •ì„± ë¶„ì„)

### ì¤‘ê¸° ê°œì„  (Medium Priority)
- [ ] ë³‘ë ¬ ì²˜ë¦¬ ë„ì…
- [ ] ìºì‹œ ê³„ì¸µí™”
- [ ] ë°ì´í„° ê²€ì¦ ë¡œì§ ê°•í™”

### ì¥ê¸° ê°œì„  (Low Priority)
- [ ] UI ëŒ€ì‹œë³´ë“œ
- [ ] ë°±í…ŒìŠ¤íŒ… ì‹œìŠ¤í…œ
- [ ] ìë™ ì•Œë¦¼

---

## ğŸ ê²°ë¡ 

**í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ**: ê¸°ë³¸ ê¸°ëŠ¥ ì‘ë™ âœ…, í’ˆì§ˆ ê°œì„  í•„ìš” âš ï¸

**ì¦‰ì‹œ ê°œì„  í•„ìš”í•œ ë¶€ë¶„**:
1. íŠ¸ë Œë“œ ì´ë¦„ ë° Impact Score (Priority 1)
2. ë¦¬ìŠ¤í¬ ë¶„ë¥˜ ë¡œì§ (Priority 1)
3. ë³´ê³ ì„œ ìƒì„¸ë„ (Priority 2)

**ì‹œìŠ¤í…œ ì‹ ë¢°ë„**:
- ë°ì´í„° ìˆ˜ì§‘: 85% âœ…
- ë°ì´í„° ë¶„ì„: 70% âš ï¸
- ë³´ê³ ì„œ í’ˆì§ˆ: 60% âš ï¸

**ë‹¤ìŒ ë‹¨ê³„**: Priority 1 ê°œì„ ì‚¬í•­ ì ìš© â†’ ì¬í…ŒìŠ¤íŠ¸ â†’ Git í‘¸ì‹œ

