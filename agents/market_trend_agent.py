"""
Clean MarketTrendAgent implementation.
Collects EV-related news via a bootstrap search and returns a structured result
expected by the workflow graph.
"""

from typing import Dict, Any, List
from datetime import datetime
from tools.gnews_tool import GNewsTool
from tools.dart_tagger import DARTTagger
from tools.sec_tagger import SECTagger
from tools.sec_edgar_tools import SECEdgarTool
from tools.trend_analysis_tools import TrendAnalyzer  # ğŸ†• íŠ¸ë Œë“œ ë¶„ì„ ë„êµ¬


class MarketTrendAgent:
    def __init__(self, web_search_tool, llm_tool, dart_tool=None):
        self.web_search_tool = web_search_tool
        self.llm_tool = llm_tool
        self.dart_tool = dart_tool
        self.gnews_tool = GNewsTool()  # GNews ë„êµ¬ ì¶”ê°€
        self.dart_tagger = DARTTagger(dart_tool=dart_tool) if dart_tool else None  # DART Tagger ì¶”ê°€
        self.sec_tool = SECEdgarTool()  # SEC EDGAR ë„êµ¬ ì¶”ê°€
        self.sec_tagger = SECTagger(sec_tool=self.sec_tool)  # SEC Tagger ì¶”ê°€
        self.trend_analyzer = TrendAnalyzer()  # ğŸ†• íŠ¸ë Œë“œ ë¶„ì„ê¸°

    def analyze_market_trends(self, state: Dict[str, Any]) -> Dict[str, Any]:
        try:
            print("\n============================")
            print("[MarketTrendAgent] Start")
            print("============================")

            news_articles = self._collect_news_articles_bootstrap(state)

            # DART ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘
            disclosure_data = self._collect_disclosures(news_articles, state)
            
            # ê³µì‹œ ë°ì´í„°ë¥¼ stateì— ì €ì¥
            state['disclosure_data'] = disclosure_data

            # ğŸ†• íŠ¸ë Œë“œ ë¶„ì„ (ë¶ˆìš©ì–´ ì œê±° + Fallback ê·œì¹™)
            print("\n    ========================================")
            print("    [íŠ¸ë Œë“œ ë¶„ì„ ì‹œì‘]")
            print("    ========================================")
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ (ë¶ˆìš©ì–´ ì œê±°ë¨) - returns Dict[str, List[Tuple[str, int]]]
            keywords_with_counts = self.trend_analyzer.extract_keywords(news_articles, top_n=20)
            
            # íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ì„± ìœ ì§€)
            categorized_keywords = {}
            for category, keyword_list in keywords_with_counts.items():
                # Extract only keywords (ignore counts)
                categorized_keywords[category] = [kw for kw, count in keyword_list]
            
            # íŠ¸ë Œë“œ ë¶„ì„ (ìµœì†Œ 3ê°œ ë³´ì¥)
            market_trends = self.trend_analyzer.analyze_trends_with_fallback(
                news_articles,
                clustering_result=[]  # ê¸°ì¡´ êµ°ì§‘í™” ê²°ê³¼ ì—†ìŒ
            )
            
            print(f"    âœ… {len(market_trends)}ê°œ íŠ¸ë Œë“œ ì‹ë³„")
            print(f"    âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ (companies: {len(categorized_keywords.get('companies', []))}ê°œ)")
            print("    ========================================\n")

            result = self._structure_analysis_result(
                news_articles, disclosure_data, [], categorized_keywords, market_trends, state
            )

            # ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
            print("\n============================")
            print("[MarketTrendAgent] ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            print("============================")
            print(f"ğŸ“° ë‰´ìŠ¤ ê¸°ì‚¬: {len(news_articles)}ê°œ")
            print(f"ğŸ“‹ ê³µì‹œ/ì¬ë¬´ ë°ì´í„°: {len(disclosure_data)}ê°œ")
            
            if len(news_articles) == 0:
                print("\nâš ï¸  ê²½ê³ : ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
                print("   â†’ ì›¹ ì„œì¹˜ê°€ ì‹¤íŒ¨í–ˆê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            if len(disclosure_data) == 0:
                print("\nâš ï¸  ê²½ê³ : ê³µì‹œ/ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
                print("   â†’ ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.")
            
            if len(news_articles) == 0 and len(disclosure_data) == 0:
                print("\nâŒ ì¤‘ìš”: ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨!")
                print("   â†’ ì¸í„°ë„· ì—°ê²°, API í‚¤, API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            print("============================\n")
            
            return result

        except Exception as e:
            print(f"MarketTrendAgent error: {e}")
            return {
                'news_articles': [],
                'disclosure_data': [],
                'analyst_reports': [],
                'keywords': [],
                'categorized_keywords': {},
                'market_trends': [],
                'analysis_metadata': {
                    'status': 'failed',
                    'timestamp': datetime.now().isoformat(),
                    'error': str(e)
                }
            }

    def _collect_news_articles_bootstrap(self, state: Dict[str, Any]) -> List[Dict[str, Any]]:
        articles: List[Dict[str, Any]] = []
        # configì—ì„œ ìµœëŒ€ ë‰´ìŠ¤ ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: 10)
        max_articles = state.get('config', {}).get('max_news_articles', 10)
        
        print("\n    ========================================")
        print("    [ì›¹ ì„œì¹˜ë¥¼ í†µí•œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘]")
        print("    ========================================")
        print("    Tavilyë¥¼ ì‚¬ìš©í•œ ìµœê·¼ ì „ê¸°ì°¨ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        
        web_search_failed = False
        
        # GNews ê±´ë„ˆë›°ê³  ë°”ë¡œ Tavily ì›¹ ê²€ìƒ‰ ì‚¬ìš© (4000 í¬ë ˆë”§)
        if True:  # í•­ìƒ ì›¹ ê²€ìƒ‰ ì‚¬ìš©
            print("    Tavily ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘...")
            # ë‰´ìŠ¤ ì¤‘ì‹¬ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ (ìµœì‹ ì„± ê°•ì¡°)
            seed_queries = [
                # ìµœì‹  íŠ¸ë Œë“œ
                "electric vehicle news today",
                "EV market trends 2024 latest",
                "battery technology news this week",
                "Tesla latest news announcement",
                
                # ê³µê¸‰ë§ & ê¸°ì—… ë‰´ìŠ¤
                "EV supply chain news recent",
                "electric vehicle battery supplier news",
                "automotive industry news EV",
                
                # í•œêµ­ ê¸°ì—…
                "LG Energy Solution latest news",
                "Samsung SDI battery news today",
                "SK On battery plant news",
                "Hyundai Kia electric vehicle news",
                
                # í•´ì™¸ ê¸°ì—…
                "CATL battery news China",
                "GM electric vehicle announcement",
                "Ford EV production news",
                "BYD electric vehicle sales",
                
                # ê¸°ìˆ  & ì •ì±…
                "EV charging infrastructure latest",
                "electric vehicle policy news",
                "battery recycling technology news",
                
                # íˆ¬ì & ì‹œì¥
                "EV stock market news",
                "electric vehicle sales report",
                "battery material shortage news"
            ]
            
            for i, q in enumerate(seed_queries):
                if len(articles) >= max_articles:
                    break
                    
                try:
                    remaining = max_articles - len(articles)
                    results_needed = min(5, remaining)  # ì¿¼ë¦¬ë‹¹ 5ê°œë¡œ ëŒ€í­ ì¦ê°€
                    
                    print(f"    [{i+1}/{len(seed_queries)}] '{q}' ì›¹ ê²€ìƒ‰ ì¤‘... (ë‚¨ì€ ìë¦¬: {remaining}ê°œ)")
                    results = self.web_search_tool.search(q, num_results=results_needed)
                    
                    if not results:
                        print(f"    [ê²½ê³ ] '{q}': ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤ (ì›¹ ì„œì¹˜ ì‹¤íŒ¨ ë˜ëŠ” ì •ë³´ ì—†ìŒ)")
                        web_search_failed = True
                    else:
                        for r in results:
                            if len(articles) >= max_articles:
                                break
                            articles.append({
                                'title': r.get('title', ''),
                                'url': r.get('url', ''),
                                'content': r.get('content', ''),
                                'publishedAt': r.get('date'),
                                'source': 'web_search',
                                'query': q
                            })
                        
                        print(f"    [OK] {len(results)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ (ì´ {len(articles)}ê°œ)")
                    
                except Exception as e:
                    print(f"    [ê²½ê³ ] '{q}' ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    print(f"    â†’ í•´ë‹¹ ê²€ìƒ‰ì–´ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    web_search_failed = True
                    continue
        
        # 3. ìµœê·¼ Nì¼ ì´ë‚´ í•„í„°ë§ (configì—ì„œ ì„¤ì •)
        days_ago = state.get('config', {}).get('days_ago', 7)
        articles = self._filter_recent_articles(articles, days=days_ago)
        
        # 4. ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        articles = articles[:max_articles]
        
        # 5. ê²°ê³¼ ìš”ì•½
        print("    ========================================")
        if len(articles) == 0:
            print("    âš ï¸  [ê²½ê³ ] ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
            print("    â†’ ì›¹ ì„œì¹˜ê°€ ì‹¤íŒ¨í–ˆê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("    â†’ ê¸°ë³¸ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µì‹œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
        elif len(articles) < 10:
            print(f"    âš ï¸  [ì£¼ì˜] ë‰´ìŠ¤ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {len(articles)}ê°œ")
            print("    â†’ ì¼ë¶€ ì›¹ ì„œì¹˜ê°€ ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print(f"    âœ… [ì„±ê³µ] ì´ {len(articles)}ê°œ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ (ìµœê·¼ {days_ago}ì¼ ì´ë‚´)")
        print("    ========================================\n")
        
        return articles

    def _filter_recent_articles(self, articles: List[Dict[str, Any]], days: int = 7) -> List[Dict[str, Any]]:
        """
        ìµœê·¼ Nì¼ ì´ë‚´ ë‰´ìŠ¤ë§Œ í•„í„°ë§í•˜ê³  ì‹œê°„ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        """
        from datetime import datetime, timedelta
        
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_articles = []
        
        for article in articles:
            published_at = article.get('publishedAt', '')
            if published_at:
                try:
                    # ISO í˜•ì‹ ë‚ ì§œ íŒŒì‹±
                    if 'T' in published_at:
                        pub_date = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
                    else:
                        pub_date = datetime.fromisoformat(published_at)
                    
                    if pub_date >= cutoff_date:
                        # ì‹œê°„ ê°€ì¤‘ì¹˜ ê³„ì‚° (ìµœê·¼ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
                        days_ago = (datetime.now() - pub_date.replace(tzinfo=None)).days
                        
                        if days_ago <= 7:
                            weight = 1.0  # 1ì£¼ì¼ ì´ë‚´ - ìµœê³  ê°€ì¤‘ì¹˜
                        elif days_ago <= 14:
                            weight = 0.8  # 2ì£¼ ì´ë‚´
                        elif days_ago <= 21:
                            weight = 0.6  # 3ì£¼ ì´ë‚´
                        elif days_ago <= 28:
                            weight = 0.4  # 4ì£¼ ì´ë‚´
                        else:
                            weight = 0.2  # ê·¸ ì´ìƒ
                        
                        article['time_weight'] = weight
                        article['days_ago'] = days_ago
                        recent_articles.append(article)
                except:
                    # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¤‘ê°„ ê°€ì¤‘ì¹˜ë¡œ í¬í•¨
                    article['time_weight'] = 0.5
                    article['days_ago'] = 15
                    recent_articles.append(article)
            else:
                # ë‚ ì§œ ì •ë³´ê°€ ì—†ìœ¼ë©´ ë‚®ì€ ê°€ì¤‘ì¹˜ë¡œ í¬í•¨
                article['time_weight'] = 0.3
                article['days_ago'] = 30
                recent_articles.append(article)
        
        # ì‹œê°„ ê°€ì¤‘ì¹˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœê·¼ ê¸°ì‚¬ê°€ ë¨¼ì €)
        recent_articles.sort(key=lambda x: x.get('time_weight', 0), reverse=True)
        
        print(f"    [FILTER] ìµœê·¼ {days}ì¼ ì´ë‚´ ê¸°ì‚¬: {len(recent_articles)}ê°œ")
        
        # ê°€ì¤‘ì¹˜ ë¶„í¬ ì¶œë ¥
        weight_distribution = {
            '1.0 (1ì£¼ì¼)': len([a for a in recent_articles if a.get('time_weight') == 1.0]),
            '0.8 (2ì£¼ì¼)': len([a for a in recent_articles if a.get('time_weight') == 0.8]),
            '0.6 (3ì£¼ì¼)': len([a for a in recent_articles if a.get('time_weight') == 0.6]),
            '0.4 (4ì£¼ì¼)': len([a for a in recent_articles if a.get('time_weight') == 0.4]),
            'ê¸°íƒ€': len([a for a in recent_articles if a.get('time_weight', 0) < 0.4])
        }
        print(f"    [WEIGHT] ê°€ì¤‘ì¹˜ ë¶„í¬: {weight_distribution}")
        
        return recent_articles

    def _collect_disclosures(
        self, 
        news_articles: List[Dict[str, Any]], 
        state: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ê¸°ì—…ëª…ì„ ì¶”ì¶œí•˜ì—¬ ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘
        - í•œêµ­ ê¸°ì—…: DART ê³µì‹œ
        - ë¯¸êµ­ ê¸°ì—…: SEC EDGAR ê³µì‹œ
        - ê·¸ ì™¸: Yahoo Finance (ì¬ë¬´ ì •ë³´ë§Œ)
        """
        disclosure_data = []
        
        # ì›¹ ì„œì¹˜ ì‹¤íŒ¨ ì‹œ relaxed mode í™œì„±í™”
        relaxed_mode = state.get('config', {}).get('relaxed_mode', True)
        
        # 1. ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        all_text = ' '.join([
            f"{article.get('title', '')} {article.get('content', '')}" 
            for article in news_articles
        ]) if news_articles else ""
        
        # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
        using_default_list = False
        if not all_text.strip():
            print("    âš ï¸  [ê²½ê³ ] ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤!")
            print("    â†’ ì›¹ ì„œì¹˜ ì‹¤íŒ¨ë¡œ ì¸í•´ ë‰´ìŠ¤ì—ì„œ ê¸°ì—…ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("    â†’ ëŒ€ì‹  ê¸°ë³¸ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µì‹œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
            korean_companies = ['LGì—ë„ˆì§€ì†”ë£¨ì…˜', 'ì‚¼ì„±SDI', 'SKì˜¨', 'í˜„ëŒ€ìë™ì°¨', 'ê¸°ì•„']
            overseas_companies = ['Tesla', 'GM', 'Ford', 'BMW', 'BYD']
            using_default_list = True
        else:
            # í•œêµ­ ê¸°ì—… ì¶”ì¶œ
            korean_companies = self.dart_tagger.extract_company_names(all_text) if self.dart_tagger else []
            # í•´ì™¸ ê¸°ì—… ì¶”ì¶œ
            overseas_companies = self.sec_tagger.extract_company_names(all_text)
        
        # ì¶”ì¶œëœ ê¸°ì—…ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
        if not using_default_list:
            if not korean_companies and not overseas_companies:
                print("    âš ï¸  [ê²½ê³ ] ë‰´ìŠ¤ì—ì„œ EV ê´€ë ¨ ê¸°ì—…ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
                print("    â†’ ë‰´ìŠ¤ ë‚´ìš©ì— EV ê¸°ì—…ëª…ì´ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                print("    â†’ ëŒ€ì‹  ê¸°ë³¸ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                using_default_list = True
            
            if not korean_companies:
                korean_companies = ['LGì—ë„ˆì§€ì†”ë£¨ì…˜', 'ì‚¼ì„±SDI', 'SKì˜¨']
            if not overseas_companies:
                overseas_companies = ['Tesla', 'GM', 'Ford']
        
        # í•´ì™¸ ê¸°ì—…ì„ ë°ì´í„° ì†ŒìŠ¤ë³„ë¡œ ë¶„ë¥˜
        classified_companies = self.sec_tagger.classify_companies_by_source(overseas_companies)
        sec_companies = classified_companies.get('SEC', [])
        yahoo_companies = classified_companies.get('Yahoo', [])
        
        print("\n    ========================================")
        print("    [ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘ ì „ëµ]")
        print("    ========================================")
        if using_default_list:
            print("    ğŸ“‹ ë°ì´í„° ì†ŒìŠ¤: ê¸°ë³¸ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ (ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ)")
        else:
            print("    ğŸ“° ë°ì´í„° ì†ŒìŠ¤: ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì¶”ì¶œ")
        print(f"    - í•œêµ­ ê¸°ì—… (DART): {len(korean_companies)}ê°œ")
        print(f"    - ë¯¸êµ­ ê¸°ì—… (SEC): {len(sec_companies)}ê°œ")
        print(f"    - ê·¸ ì™¸ ê¸°ì—… (Yahoo Finance): {len(yahoo_companies)}ê°œ")
        print(f"    - Relaxed Mode: {'í™œì„±í™”' if relaxed_mode else 'ë¹„í™œì„±í™”'}")
        print("    ========================================\n")
        
        # ==============================================
        # 1) í•œêµ­ ê¸°ì—… - DART ê³µì‹œ
        # ==============================================
        if self.dart_tool and self.dart_tagger and korean_companies:
            disclosure_data.extend(
                self._collect_dart_disclosures(korean_companies, state, relaxed_mode)
            )
        
        # ==============================================
        # 2) ë¯¸êµ­ ê¸°ì—… - SEC EDGAR ê³µì‹œ
        # ==============================================
        if sec_companies:
            disclosure_data.extend(
                self._collect_sec_disclosures(sec_companies, state, relaxed_mode)
            )
        
        # ==============================================
        # 3) ê·¸ ì™¸ ê¸°ì—… - Yahoo Finance (ì¬ë¬´ ì •ë³´)
        # ==============================================
        if yahoo_companies:
            disclosure_data.extend(
                self._collect_yahoo_data(yahoo_companies, state, relaxed_mode)
            )
        
        # ìµœì¢… ìš”ì•½
        print("\n    ========================================")
        print("    [ê³µì‹œ/ì¬ë¬´ ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½]")
        print("    ========================================")
        if len(disclosure_data) == 0:
            print("    âŒ [ì‹¤íŒ¨] ê³µì‹œ/ì¬ë¬´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
            print("    â†’ ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤(DART/SEC/Yahoo)ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.")
            print("    â†’ ë‰´ìŠ¤ ë°ì´í„°ë§Œìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í•˜ê±°ë‚˜, API ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        elif len(disclosure_data) < 5:
            print(f"    âš ï¸  [ì£¼ì˜] ê³µì‹œ/ì¬ë¬´ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {len(disclosure_data)}ê°œ")
            print("    â†’ ì¼ë¶€ ë°ì´í„° ì†ŒìŠ¤ì—ì„œë§Œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print(f"    âœ… [ì„±ê³µ] ì´ {len(disclosure_data)}ê°œ ê³µì‹œ/ì¬ë¬´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        print("    ========================================\n")
        
        return disclosure_data
    
    def _collect_dart_disclosures(
        self, 
        company_names: List[str], 
        state: Dict[str, Any],
        relaxed_mode: bool
    ) -> List[Dict[str, Any]]:
        """í•œêµ­ ê¸°ì—… DART ê³µì‹œ ìˆ˜ì§‘"""
        disclosure_data = []
        
        try:
            print("\n    ========================================")
            print("    [í•œêµ­ ê¸°ì—… ê³µì‹œ ìˆ˜ì§‘ - DART]")
            print("    ========================================")
            
            print(f"    [OK] ê³µì‹œ ìˆ˜ì§‘ ëŒ€ìƒ í•œêµ­ ê¸°ì—…: {len(company_names)}ê°œ")
            for company in company_names[:5]:
                print(f"        - {company}")
            if len(company_names) > 5:
                print(f"        ... ì™¸ {len(company_names) - 5}ê°œ")
            
            # ê° ê¸°ì—…ì˜ ìµœê·¼ ê³µì‹œ ìˆ˜ì§‘
            days_ago = state.get('config', {}).get('days_ago', 30)
            max_disclosures = state.get('config', {}).get('max_disclosures_per_company', 10)
            
            all_disclosures = []
            for company in company_names:
                try:
                    company_disclosures = self.dart_tagger.collect_company_disclosures(
                        [company], 
                        days=days_ago
                    )
                    all_disclosures.extend(company_disclosures[:max_disclosures])
                except Exception as e:
                    if relaxed_mode:
                        print(f"    [WARNING] {company} ê³µì‹œ ìˆ˜ì§‘ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                    else:
                        raise
            
            # EV ê´€ë ¨ ê³µì‹œë§Œ í•„í„°ë§
            if all_disclosures:
                # relaxed_modeì—ì„œëŠ” í•„í„°ë§ ê¸°ì¤€ ì™„í™”
                # EV ê¸°ì—…ì˜ ê³µì‹œëŠ” ëª¨ë‘ EV ê´€ë ¨ìœ¼ë¡œ ê°„ì£¼ (strict=False)
                if relaxed_mode:
                    ev_disclosures = self.dart_tagger.filter_ev_disclosures(all_disclosures, strict=False)
                    print(f"    [INFO] Relaxed mode: EV ê¸°ì—…ì˜ ëª¨ë“  ê³µì‹œ í¬í•¨")
                else:
                    ev_disclosures = self.dart_tagger.filter_ev_disclosures(all_disclosures, strict=True)
                
                disclosure_data = ev_disclosures
                
                print(f"    [OK] ì´ {len(all_disclosures)}ê°œ ê³µì‹œ ì¤‘ {len(ev_disclosures)}ê°œ ì„ ë³„")
                
                # ìš”ì•½ í†µê³„
                summary = self.dart_tagger.get_disclosure_summary(ev_disclosures)
                print(f"    [SUMMARY] ê³µì‹œ í†µê³„:")
                print(f"        - ì „ì²´: {summary['total']}ê°œ")
                print(f"        - ì¤‘ìš”ë„ (High/Medium/Low): {summary['by_importance']['high']}/{summary['by_importance']['medium']}/{summary['by_importance']['low']}")
                print(f"        - EV ê´€ë ¨: {summary['ev_related']}ê°œ")
                
                if summary['recent_important']:
                    print(f"    [IMPORTANT] ì£¼ìš” ê³µì‹œ (ìµœëŒ€ 3ê°œ):")
                    for disc in summary['recent_important'][:3]:
                        print(f"        - [{disc['company']}] {disc['title'][:50]}... ({disc['date']})")
            else:
                print("    âš ï¸  [ê²½ê³ ] DART ê³µì‹œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
                print("    â†’ í•´ë‹¹ ê¸°ì—…ì˜ ê³µì‹œê°€ ê¸°ê°„ ë‚´ì— ì—†ê±°ë‚˜ API í˜¸ì¶œì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                print("    â†’ í•œêµ­ ê¸°ì—… ê³µì‹œ ì •ë³´ ì—†ì´ ë¶„ì„ì„ ê³„ì†í•©ë‹ˆë‹¤.")
            
            print("    ========================================\n")
            
        except Exception as e:
            print(f"    [ERROR] DART ê³µì‹œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            if not relaxed_mode:
                import traceback
                traceback.print_exc()
        
        return disclosure_data
    
    def _collect_sec_disclosures(
        self, 
        company_names: List[str], 
        state: Dict[str, Any],
        relaxed_mode: bool
    ) -> List[Dict[str, Any]]:
        """ë¯¸êµ­ ê¸°ì—… SEC EDGAR ê³µì‹œ ìˆ˜ì§‘"""
        disclosure_data = []
        
        try:
            print("\n    ========================================")
            print("    [ë¯¸êµ­ ê¸°ì—… ê³µì‹œ ìˆ˜ì§‘ - SEC EDGAR]")
            print("    ========================================")
            
            print(f"    [OK] ê³µì‹œ ìˆ˜ì§‘ ëŒ€ìƒ ë¯¸êµ­ ê¸°ì—…: {len(company_names)}ê°œ")
            for company in company_names[:5]:
                print(f"        - {company}")
            if len(company_names) > 5:
                print(f"        ... ì™¸ {len(company_names) - 5}ê°œ")
            
            # ê° ê¸°ì—…ì˜ ìµœê·¼ ê³µì‹œ ìˆ˜ì§‘
            max_sec_filings = state.get('config', {}).get('max_sec_filings_per_company', 8)
            overseas_filings = self.sec_tagger.collect_company_filings(
                company_names,
                max_filings=max_sec_filings,
                relaxed_mode=relaxed_mode
            )
            
            # EV ê´€ë ¨ ê³µì‹œë§Œ í•„í„°ë§
            if overseas_filings:
                # relaxed_modeì—ì„œëŠ” ëª¨ë“  ê³µì‹œ í¬í•¨ (EV ê¸°ì—…ì˜ ê³µì‹œëŠ” ëª¨ë‘ ê´€ë ¨ì„± ìˆìŒ)
                if relaxed_mode:
                    # ê° ê³µì‹œì— EV ê´€ë ¨ íƒœê·¸ ìë™ ì¶”ê°€
                    for filing in overseas_filings:
                        company_name = filing.get('company_name', '')
                        if 'tags' not in filing:
                            filing['tags'] = {
                                'importance': 'high',
                                'is_ev_related': True,
                                'ev_keywords': [f'{company_name} (EV ê¸°ì—…)'],
                                'tagged_at': datetime.now().isoformat()
                            }
                        else:
                            filing['tags']['is_ev_related'] = True
                    ev_filings = overseas_filings
                    print(f"    [INFO] Relaxed mode: EV ê¸°ì—…ì˜ ëª¨ë“  ê³µì‹œ í¬í•¨")
                else:
                    ev_filings = self.sec_tagger.filter_ev_filings(overseas_filings)
                
                disclosure_data = ev_filings
                
                print(f"    [OK] ì´ {len(overseas_filings)}ê°œ ê³µì‹œ ì¤‘ {len(ev_filings)}ê°œ ì„ ë³„")
                
                # ìš”ì•½ í†µê³„
                summary = self.sec_tagger.get_filing_summary(ev_filings)
                print(f"    [SUMMARY] SEC ê³µì‹œ í†µê³„:")
                print(f"        - ì „ì²´: {summary['total']}ê°œ")
                print(f"        - ì¤‘ìš”ë„ (High/Medium/Low): {summary['by_importance']['high']}/{summary['by_importance']['medium']}/{summary['by_importance']['low']}")
                print(f"        - EV ê´€ë ¨: {summary['ev_related']}ê°œ")
                
                if summary['recent_important']:
                    print(f"    [IMPORTANT] ì£¼ìš” ê³µì‹œ (ìµœëŒ€ 3ê°œ):")
                    for disc in summary['recent_important'][:3]:
                        print(f"        - [{disc['company']}] {disc['title']} ({disc['date']})")
            else:
                print("    âš ï¸  [ê²½ê³ ] SEC ê³µì‹œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
                print("    â†’ í•´ë‹¹ ê¸°ì—…ì˜ SEC ê³µì‹œê°€ ì—†ê±°ë‚˜ API í˜¸ì¶œì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                print("    â†’ ë¯¸êµ­ ê¸°ì—… ê³µì‹œ ì •ë³´ ì—†ì´ ë¶„ì„ì„ ê³„ì†í•©ë‹ˆë‹¤.")
            
            print("    ========================================\n")
            
        except Exception as e:
            print(f"    [ERROR] SEC ê³µì‹œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            if not relaxed_mode:
                import traceback
                traceback.print_exc()
        
        return disclosure_data
    
    def _collect_yahoo_data(
        self, 
        company_names: List[str], 
        state: Dict[str, Any],
        relaxed_mode: bool
    ) -> List[Dict[str, Any]]:
        """ê·¸ ì™¸ ê¸°ì—… Yahoo Finance ì¬ë¬´ ì •ë³´ ìˆ˜ì§‘"""
        yahoo_data = []
        
        try:
            print("\n    ========================================")
            print("    [ê·¸ ì™¸ ê¸°ì—… ì¬ë¬´ ì •ë³´ ìˆ˜ì§‘ - Yahoo Finance]")
            print("    ========================================")
            
            print(f"    [OK] ì¬ë¬´ ì •ë³´ ìˆ˜ì§‘ ëŒ€ìƒ ê¸°ì—…: {len(company_names)}ê°œ")
            for company in company_names[:5]:
                print(f"        - {company}")
            if len(company_names) > 5:
                print(f"        ... ì™¸ {len(company_names) - 5}ê°œ")
            
            # Yahoo Finance ë„êµ¬ import
            from tools.yahoo_finance_tools import YahooFinanceTool
            yahoo_tool = YahooFinanceTool()
            
            for company_name in company_names:
                try:
                    # í‹°ì»¤ ì‹¬ë³¼ ê°€ì ¸ì˜¤ê¸°
                    company_info = self.sec_tagger.OVERSEAS_EV_COMPANIES.get(company_name, {})
                    ticker = company_info.get('ticker')
                    
                    if not ticker:
                        if not relaxed_mode:
                            print(f"    [WARNING] {company_name}: í‹°ì»¤ ì‹¬ë³¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                    
                    # ì¬ë¬´ ë°ì´í„° ìƒì„± (ê³µì‹œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜)
                    financial_info = {
                        'company_name': company_name,
                        'title': f'{company_name} - Yahoo Finance ì¬ë¬´ ì •ë³´',
                        'ticker': ticker,
                        'date': datetime.now().strftime('%Y%m%d'),
                        'source': 'Yahoo Finance',
                        'country': company_info.get('country', 'Unknown'),
                        'tags': {
                            'importance': 'medium',
                            'is_ev_related': True,
                            'ev_keywords': ['EV', 'electric vehicle'],
                            'tagged_at': datetime.now().isoformat()
                        }
                    }
                    
                    yahoo_data.append(financial_info)
                    print(f"    [OK] {company_name} ({ticker}): ì¬ë¬´ ì •ë³´ ìˆ˜ì§‘")
                    
                except Exception as e:
                    if relaxed_mode:
                        print(f"    [WARNING] {company_name} ì¬ë¬´ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                    else:
                        print(f"    [ERROR] {company_name} ì¬ë¬´ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            
            print(f"    [OK] ì´ {len(yahoo_data)}ê°œ ê¸°ì—…ì˜ ì¬ë¬´ ì •ë³´ ìˆ˜ì§‘")
            print("    ========================================\n")
            
        except Exception as e:
            print(f"    [ERROR] Yahoo Finance ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            if not relaxed_mode:
                import traceback
                traceback.print_exc()
        
        return yahoo_data

    def _extract_and_categorize_keywords(
        self,
        news_articles: List[Dict[str, Any]],
        disclosure_data: List[Dict[str, Any]],
        analyst_reports: List[Dict[str, Any]],
    ) -> Dict[str, List[str]]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¶„ë¥˜ (ì‹œê°„ ê°€ì¤‘ì¹˜ ì ìš©)"""
        import re
        from collections import Counter

        # ì£¼ìš” ì „ê¸°ì°¨ ê´€ë ¨ ê¸°ì—… (í•œêµ­ì–´ + ì˜ì–´)
        ev_companies = [
            # í•œêµ­ ë°°í„°ë¦¬
            'ì‚¼ì„±SDI', 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', 'SKì˜¨', 'ì—ì½”í”„ë¡œ',
            # í•œêµ­ ì•½ì–´
            'LG', 'LGì—ë„ˆì§€', 'SDI', 'SK', 'SKì´ë…¸ë² ì´ì…˜',
            'í˜„ëŒ€ì°¨', 'ê¸°ì•„', 'í¬ìŠ¤ì½”', 'ì—˜ì•¤ì—í”„',
            # í•œêµ­ ë¶€í’ˆ/ì†Œì¬
            'ì†”ë£¨ìŠ¤ì²¨ë‹¨ì†Œì¬', 'LGì „ì', 'LS', 'í›„ì„±',
            # í•´ì™¸ ì™„ì„±ì°¨
            'Tesla', 'í…ŒìŠ¬ë¼', 'BYD', 'BMW', 'Mercedes', 'ë²¤ì¸ ',
            'Volkswagen', 'í­ìŠ¤ë°”ê²', 'GM', 'Ford', 'í¬ë“œ',
            'Nio', 'Xpeng', 'Li Auto', 'Lucid', 'Rivian',
            # í•´ì™¸ ë°°í„°ë¦¬
            'CATL', 'Panasonic', 'íŒŒë‚˜ì†Œë‹‰', 'BYD Battery',
        ]

        # í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ì‹œê°„ ê°€ì¤‘ì¹˜ ê³ ë ¤)
        weighted_texts: List[tuple] = []
        for a in news_articles:
            text = (a.get('title') or '') + ' ' + (a.get('content') or '')
            weight = a.get('time_weight', 0.5)
            weighted_texts.append((text, weight))
        
        # ê°€ì¤‘ì¹˜ë¥¼ ê³ ë ¤í•œ í…ìŠ¤íŠ¸ ë¸”ë¡­ ìƒì„± (ìµœê·¼ ê¸°ì‚¬ë¥¼ ë” ë§ì´ ë°˜ë³µ)
        blob_parts = []
        for text, weight in weighted_texts:
            # ê°€ì¤‘ì¹˜ì— ë”°ë¼ í…ìŠ¤íŠ¸ë¥¼ ë°˜ë³µ (1.0 = 1ë²ˆ, 0.8 = 0.8ë²ˆ, ...)
            repetitions = int(weight * 2)  # ìµœëŒ€ 2ë²ˆ ë°˜ë³µ
            if repetitions > 0:
                blob_parts.extend([text] * repetitions)
            else:
                blob_parts.append(text)
        
        blob = ' '.join(blob_parts)

        # ê¸°ì—…ëª… ì¶”ì¶œ (ê°€ì¤‘ì¹˜ ê³ ë ¤)
        company_counts = Counter()
        for text, weight in weighted_texts:
            for company in ev_companies:
                if company in text:
                    # ê°€ì¤‘ì¹˜ë¥¼ ê³±í•˜ì—¬ ì¹´ìš´íŠ¸
                    company_counts[company] += weight
        
        # ìƒìœ„ ê¸°ì—…ëª… ì¶”ì¶œ (ê°€ì¤‘ì¹˜ í•©ê³„ ê¸°ì¤€)
        found_companies = [company for company, _ in company_counts.most_common(30)]

        # í‚¤ì›Œë“œ ì¶”ì¶œ (ì˜ì–´, ê°€ì¤‘ì¹˜ ì ìš©)
        keyword_counts = Counter()
        for text, weight in weighted_texts:
            tokens = re.findall(r"[A-Za-z][A-Za-z0-9\-\+]+", text)
            for token in tokens:
                if len(token) > 2:
                    keyword_counts[token.lower()] += weight
        
        top_keywords = [w for (w, _) in keyword_counts.most_common(30)]

        # í•œêµ­ ê¸°ì—…ëª… ì¶”ì¶œ (ê°€ì¤‘ì¹˜ ì ìš©)
        korean_company_counts = Counter()
        for text, weight in weighted_texts:
            korean_companies = re.findall(r'[ê°€-í£]+(?:ì „ì|SDI|ì—ë„ˆì§€|ì†”ë£¨ì…˜|ì´ë…¸ë² ì´ì…˜|ì¼€ë¯¸ì¹¼|ì†Œì¬)', text)
            for company in korean_companies:
                korean_company_counts[company] += weight
        
        found_companies.extend([c for c, _ in korean_company_counts.most_common(10)])

        #  
        found_companies = list(set(found_companies))
        
        # ë¬´ì˜ë¯¸í•œ í‚¤ì›Œë“œ í•„í„°ë§
        def is_valid_keyword(keyword: str) -> bool:
            """ìœ íš¨í•œ í‚¤ì›Œë“œì¸ì§€ ê²€ì‚¬"""
            if not keyword or not keyword.strip():
                return False
            if keyword.strip() in ['-', '_', '/', '\\', '|', '.', ',']:
                return False
            if len(keyword.strip()) < 2:
                return False
            if keyword.strip().isdigit():
                return False
            return True
        
        # íšŒì‚¬ëª… í•„í„°ë§
        found_companies = [c for c in found_companies if is_valid_keyword(c)]
        
        # í‚¤ì›Œë“œ í•„í„°ë§
        top_keywords = [k for k in top_keywords if is_valid_keyword(k)]

        print(f"   [OK] ì¶”ì¶œëœ ê¸°ì—…ëª… (ê°€ì¤‘ì¹˜ ì ìš©): {len(found_companies)}")
        for company in found_companies[:10]:  # ìƒìœ„ 10ê°œ ì¶œë ¥
            weight_score = company_counts.get(company, korean_company_counts.get(company, 0))
            print(f"      - {company} (ê°€ì¤‘ì¹˜ í•©: {weight_score:.2f})")

        print(f"   [OK] ì¶”ì¶œëœ í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜ ì ìš©): {len(top_keywords)}")
        for keyword in top_keywords[:10]:
            weight_score = keyword_counts.get(keyword, 0)
            print(f"      - {keyword} (ê°€ì¤‘ì¹˜ í•©: {weight_score:.2f})")

        return {
            'companies': found_companies,  # ê¸°ì—…ëª…
            'tech': top_keywords[:10],
            'market': top_keywords[10:20],
            'investment': top_keywords[20:30],
        }

    def _structure_analysis_result(
        self,
        news_articles: List[Dict[str, Any]],
        disclosure_data: List[Dict[str, Any]],
        analyst_reports: List[Dict[str, Any]],
        categorized_keywords: Dict[str, List[str]],
        market_trends: List[Dict[str, Any]],
        state: Dict[str, Any],
    ) -> Dict[str, Any]:
        all_keywords: List[str] = []
        for v in categorized_keywords.values():
            all_keywords.extend(v)
        all_keywords = list(dict.fromkeys(all_keywords))

        #   suppliers  
        companies = categorized_keywords.get('companies', [])
        suppliers = []
        for company in companies:
            suppliers.append({
                'company': company,
                'category': ' ',
                'products': [],
                'oem_relationships': [],
                'confidence': 0.8,
                'source': 'news_extraction'
            })

        print(f"   [OK] MarketTrend  : {len(suppliers)}")

        return {
            'news_articles': news_articles,
            'disclosure_data': disclosure_data,
            'analyst_reports': analyst_reports,
            'keywords': all_keywords,
            'categorized_keywords': categorized_keywords,
            'market_trends': market_trends,
            'discovered_companies': suppliers,  #    
            'analysis_metadata': {
                'status': 'completed',
                'timestamp': datetime.now().isoformat(),
                'total_news': len(news_articles),
                'total_disclosures': len(disclosure_data),
                'total_reports': len(analyst_reports),
                'total_keywords': len(all_keywords),
                'total_trends': len(market_trends),
                'discovered_companies': len(suppliers),
            },
        }

