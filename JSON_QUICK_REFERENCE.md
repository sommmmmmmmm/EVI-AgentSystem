# JSON ì¶œë ¥ ê°•ì œ ì‹œìŠ¤í…œ - Quick Reference

## ğŸš€ 5ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from tools.json_parser import parse_llm_json
from prompts.json_output_templates import (
    get_risk_analysis_prompt,
    RISK_ANALYSIS_SCHEMA,
    get_json_llm_config
)

# Step 1: JSON-only í”„ë¡¬í”„íŠ¸ ìƒì„±
prompt = get_risk_analysis_prompt(
    company="Tesla",
    topic="Compliance",
    timeframe="2023-2024",
    analysis_text="Tesla faced regulatory investigations..."
)

# Step 2: LLM í˜¸ì¶œ (ê¶Œì¥ ì„¤ì •)
config = get_json_llm_config()
llm_output = your_llm.generate(prompt, **config)

# Step 3: íŒŒì‹± (ìë™ ìˆ˜ì • + Fallback)
result = parse_llm_json(
    llm_output,
    schema=RISK_ANALYSIS_SCHEMA,
    fallback_data={'company': 'Tesla', 'topic': 'Compliance', 'timeframe': '2023-2024'}
)
```

---

## ğŸ“š ì£¼ìš” í•¨ìˆ˜

### íŒŒì‹± (json_parser.py)

| í•¨ìˆ˜ | ìš©ë„ | ë°˜í™˜ |
|------|------|------|
| `parse_llm_json()` | ì „ì²´ íŒŒì´í”„ë¼ì¸ (ì¶”ì¶œ+ìˆ˜ì •+ê²€ì¦) | dict |
| `extract_json()` | ë§ˆí¬ë‹¤ìš´/í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ | str |
| `quick_fix_json()` | í›„í–‰ ì½¤ë§ˆ, NaN ë“± ìë™ ìˆ˜ì • | str |
| `diagnose_json_error()` | ì—ëŸ¬ ì§„ë‹¨ | str |

### í”„ë¡¬í”„íŠ¸ (json_output_templates.py)

| í•¨ìˆ˜ | ìš©ë„ | ë°˜í™˜ |
|------|------|------|
| `get_risk_analysis_prompt()` | ë¦¬ìŠ¤í¬ ë¶„ì„ í”„ë¡¬í”„íŠ¸ | str |
| `get_financial_analysis_prompt()` | ì¬ë¬´ ë¶„ì„ í”„ë¡¬í”„íŠ¸ | str |
| `get_market_trends_prompt()` | ì‹œì¥ íŠ¸ë Œë“œ í”„ë¡¬í”„íŠ¸ | str |
| `get_repair_prompt()` | ìˆ˜ì • í”„ë¡¬í”„íŠ¸ | str |
| `get_json_llm_config()` | LLM ê¶Œì¥ ì„¤ì • | dict |

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### "Expecting value: line 1 column 1"

```python
# ì§„ë‹¨
from tools.json_parser import diagnose_json_error
diagnosis = diagnose_json_error(llm_output)
print(diagnosis)

# ì›ì¸: ë¹ˆ ë¬¸ìì—´, BOM, ë§ˆí¬ë‹¤ìš´
# í•´ê²°: parse_llm_json()ì´ ìë™ ì²˜ë¦¬
```

### ë§ˆí¬ë‹¤ìš´ ì½”ë“œíœìŠ¤

```python
# âŒ LLM ì¶œë ¥
'''```json
{"key": "value"}
```'''

# âœ… ìë™ ì œê±°ë¨
result = parse_llm_json(llm_output)
```

### í›„í–‰ ì½¤ë§ˆ

```python
# âŒ LLM ì¶œë ¥
'{"key": "value",}'

# âœ… ìë™ ìˆ˜ì •ë¨ (repair_attempts=2)
result = parse_llm_json(llm_output, repair_attempts=2)
```

### NaN/Infinity

```python
# âŒ LLM ì¶œë ¥
'{"score": NaN}'

# âœ… nullë¡œ ìë™ ë³€í™˜
result = parse_llm_json(llm_output)
# â†’ {"score": None}
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### í”„ë¡¬í”„íŠ¸ ì‘ì„± ì‹œ

- [ ] JSON-only í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©
- [ ] ìŠ¤í‚¤ë§ˆë¥¼ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œ
- [ ] END_TOKEN (`<END_OF_JSON>`) ìš”êµ¬
- [ ] ì˜ˆì‹œ í¬í•¨
- [ ] "CRITICAL RULES" ëª…ì‹œ

### LLM í˜¸ì¶œ ì‹œ

- [ ] `temperature=0.1` (ë‚®ê²Œ)
- [ ] `max_tokens=4000+` (ì¶©ë¶„íˆ)
- [ ] `stop=["<END_OF_JSON>"]`
- [ ] System messageë¡œ JSON-only ê°•ì œ

### íŒŒì‹± ì‹œ

- [ ] `parse_llm_json()` ì‚¬ìš©
- [ ] `schema` íŒŒë¼ë¯¸í„° ì „ë‹¬
- [ ] `fallback_data` ì œê³µ
- [ ] `repair_attempts=2` ì„¤ì •

---

## ğŸ’¡ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. Two-Stage Approach

```python
# Stage A: ìì—°ì–´ ìš”ì•½ (ììœ  í˜•ì‹)
summary = llm.generate("Analyze Tesla's risk...")

# Stage B: JSON ë³€í™˜ (ì—„ê²©í•œ í˜•ì‹)
json_prompt = get_risk_analysis_prompt(
    company="Tesla",
    analysis_text=summary
)
result = parse_llm_json(llm.generate(json_prompt))
```

### 2. Streaming ì£¼ì˜

```python
# âŒ ë‚˜ìœ ì˜ˆ
for chunk in llm.stream(prompt):
    parse_llm_json(chunk)  # ë¶ˆì™„ì „í•œ JSON!

# âœ… ì¢‹ì€ ì˜ˆ
full_output = ''.join(llm.stream(prompt))
if "<END_OF_JSON>" in full_output:
    result = parse_llm_json(full_output)
```

### 3. ìƒì„¸ ë¡œê¹…

```python
import logging
logging.basicConfig(level=logging.INFO)

# ìë™ìœ¼ë¡œ íŒŒì‹± ê³¼ì • ë¡œê·¸ ì¶œë ¥
result = parse_llm_json(llm_output, schema=SCHEMA)
```

---

## ğŸ¯ ì„±ëŠ¥ ì§€í‘œ

| ì§€í‘œ | Before | After | ê°œì„  |
|------|--------|-------|------|
| íŒŒì‹± ì„±ê³µë¥  | 60% | 95%+ | +58% |
| ìë™ ìˆ˜ì • | ì—†ìŒ | 90% | - |
| ìˆ˜ë™ ê°œì… | 40% | 5% | -88% |

---

## ğŸ“– ë” ì•Œì•„ë³´ê¸°

- ğŸ“„ **JSON_OUTPUT_GUIDE.md** - ì „ì²´ ê°€ì´ë“œ
- ğŸ§ª **examples/json_output_example.py** - 8ê°€ì§€ ì˜ˆì‹œ
- ğŸ”§ **tools/json_parser.py** - íŒŒì„œ ì†ŒìŠ¤
- ğŸ“ **prompts/json_output_templates.py** - í”„ë¡¬í”„íŠ¸ ì†ŒìŠ¤

---

## ğŸ†˜ ë„ì›€ë§

### ì—¬ì „íˆ íŒŒì‹± ì‹¤íŒ¨?

1. **ì§„ë‹¨ ì‹¤í–‰**
   ```python
   diagnosis = diagnose_json_error(llm_output)
   print(diagnosis)
   ```

2. **ê¸¸ì´ í™•ì¸**
   ```python
   print(f"Length: {len(llm_output)}")
   print(f"First 200: {llm_output[:200]}")
   ```

3. **ìˆ˜ë™ ìˆ˜ì • í”„ë¡¬í”„íŠ¸**
   ```python
   repair_prompt = get_repair_prompt(llm_output, SCHEMA, error_msg)
   fixed_output = llm.generate(repair_prompt)
   ```

4. **Fallback ì‚¬ìš©**
   ```python
   result = parse_llm_json(
       llm_output,
       fallback_data={'company': 'X', 'topic': 'Y', 'timeframe': 'Z'}
   )
   # ì‹¤íŒ¨ ì‹œ ìµœì†Œ êµ¬ì¡° ë°˜í™˜
   ```

---

**ì‘ì„±ì¼:** 2025-10-24  
**ë²„ì „:** 1.0.0

