
# LLM JSON ì¶œë ¥ ê°•ì œ ì‹œìŠ¤í…œ ê°€ì´ë“œ

## ğŸ¯ ëª©í‘œ

LLMì´ **í•­ìƒ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥**í•˜ë„ë¡ ê°•ì œí•˜ê³ , íŒŒì‹± ì‹¤íŒ¨ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ êµ¬ì„±

### 1. **JSON íŒŒì„œ** (`tools/json_parser.py`)

ê²¬ê³ í•œ íŒŒì„œë¡œ LLM ì¶œë ¥ì—ì„œ JSONì„ ì¶”ì¶œí•˜ê³  ìë™ ìˆ˜ì •í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- âœ… ë§ˆí¬ë‹¤ìš´ ì½”ë“œíœìŠ¤ ì œê±°
- âœ… í›„í–‰ ì½¤ë§ˆ ì œê±°
- âœ… NaN/Infinity â†’ null ë³€í™˜
- âœ… BOM/ì œë¡œí­ ë¬¸ì ì œê±°
- âœ… ìë™ ìˆ˜ì • (ìµœëŒ€ 2íšŒ ì‹œë„)
- âœ… ì‹¤íŒ¨ ì‹œ Fallback ì‘ë‹µ

### 2. **JSON í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿** (`prompts/json_output_templates.py`)

LLMì´ JSONë§Œ ì¶œë ¥í•˜ë„ë¡ ê°•ì œí•˜ëŠ” í•˜ë“œ ê°€ë“œ í”„ë¡¬í”„íŠ¸

**ì£¼ìš” ê¸°ëŠ¥:**
- âœ… JSON ìŠ¤í‚¤ë§ˆ ê°•ì œ
- âœ… ì—„ê²©í•œ ê·œì¹™ ëª…ì‹œ
- âœ… END_TOKENìœ¼ë¡œ ì™„ê²°ì„± ë³´ì¥
- âœ… ì˜ˆì‹œ í¬í•¨
- âœ… ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ìƒì„±

---

## ğŸ“‹ ì œê³µë˜ëŠ” ìŠ¤í‚¤ë§ˆ

### 1. **Risk Analysis Schema**

ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ (Compliance/Governance/Sustainability ë“±)

```json
{
  "company": "Tesla",
  "topic": "Compliance",
  "timeframe": "2023-2024",
  "incidents": [
    {
      "title": "Battery safety recall",
      "date": "2023-06-15",
      "source_url": "https://example.com",
      "severity": "high",
      "description": "...",
      "financial_impact": {
        "capex": null,
        "opex": 50000000,
        "fines": 5000000
      },
      "probability": 0.8,
      "mitigation": "Enhanced QC"
    }
  ],
  "overall_risk_score": 65,
  "summary": "Moderate risk level"
}
```

### 2. **Financial Analysis Schema**

ì¬ë¬´ ë¶„ì„ ê²°ê³¼

```json
{
  "company": "Samsung SDI",
  "analysis_date": "2024-03-20",
  "metrics": {
    "revenue": 15000000000,
    "operating_profit": 1200000000,
    "net_income": 900000000,
    "total_assets": 25000000000,
    "total_equity": 18000000000,
    "total_debt": 3000000000
  },
  "ratios": {
    "roe": 0.05,
    "roa": 0.036,
    "operating_margin": 0.08,
    "debt_ratio": 0.167,
    "current_ratio": 2.5
  },
  "score": 75,
  "summary": "Solid financial performance"
}
```

### 3. **Market Trends Schema**

ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼

```json
{
  "analysis_date": "2024-03-20",
  "trends": [
    {
      "title": "Solid-state battery acceleration",
      "description": "Commercial production by 2026",
      "significance": "high",
      "time_horizon": "medium-term",
      "evidence": [
        "Toyota $10B investment",
        "Samsung SDI pilot line"
      ],
      "affected_companies": ["Toyota", "Samsung SDI"]
    }
  ],
  "key_insights": [
    "2x range improvement by 2027"
  ],
  "investment_implications": [
    "Buy solid-state battery pioneers"
  ]
}
```

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‚¬ìš©

```python
from tools.json_parser import parse_llm_json
from prompts.json_output_templates import (
    get_risk_analysis_prompt,
    RISK_ANALYSIS_SCHEMA,
    get_json_llm_config
)

# 1. JSON-only í”„ë¡¬í”„íŠ¸ ìƒì„±
prompt = get_risk_analysis_prompt(
    company="Tesla",
    topic="Compliance",
    timeframe="2023-2024",
    analysis_text="Tesla faced recall..."
)

# 2. LLM í˜¸ì¶œ (ê¶Œì¥ ì„¤ì •)
config = get_json_llm_config()
llm_output = llm.generate(prompt, **config)

# 3. ê²¬ê³ í•œ íŒŒì‹± (ìë™ ìˆ˜ì • í¬í•¨)
result = parse_llm_json(
    llm_output,
    schema=RISK_ANALYSIS_SCHEMA,
    fallback_data={
        'company': 'Tesla',
        'topic': 'Compliance',
        'timeframe': '2023-2024'
    }
)

print(result)
```

### Fallback ìˆëŠ” ì•ˆì „í•œ ì‚¬ìš©

```python
try:
    # íŒŒì‹± ì‹œë„
    result = parse_llm_json(
        llm_output,
        schema=RISK_ANALYSIS_SCHEMA,
        fallback_data={
            'company': company,
            'topic': topic,
            'timeframe': timeframe
        },
        repair_attempts=2  # ìµœëŒ€ 2íšŒ ìë™ ìˆ˜ì •
    )
    
    # ì„±ê³µ
    print(f"âœ“ Parsed: {result['company']}")
    
except Exception as e:
    # ì™„ì „ ì‹¤íŒ¨ (fallbackë„ ì‹¤íŒ¨)
    print(f"âœ— Complete failure: {e}")
```

### ìˆ˜ë™ ìˆ˜ì • í”„ë¡¬í”„íŠ¸

```python
from tools.json_parser import parse_and_validate
from prompts.json_output_templates import get_repair_prompt

# 1ì°¨ íŒŒì‹± ì‹œë„
try:
    obj, was_repaired = parse_and_validate(llm_output, schema)
except Exception as e:
    # ì‹¤íŒ¨ ì‹œ LLMì—ê²Œ ìˆ˜ì • ìš”ì²­
    repair_prompt = get_repair_prompt(
        broken_json=llm_output,
        schema=RISK_ANALYSIS_SCHEMA,
        error_message=str(e)
    )
    
    # LLM ì¬í˜¸ì¶œ
    repaired_output = llm.generate(repair_prompt)
    
    # ì¬íŒŒì‹±
    obj = parse_llm_json(repaired_output, schema=RISK_ANALYSIS_SCHEMA)
```

---

## ğŸ”§ í•µì‹¬ ê¸°ëŠ¥ ìƒì„¸

### 1. **extract_json()** - JSON ì¶”ì¶œ

ë§ˆí¬ë‹¤ìš´, ìì—°ì–´ ë“±ì—ì„œ JSONë§Œ ì¶”ì¶œ

```python
from tools.json_parser import extract_json

# ì…ë ¥
text = '''Here's the result:
```json
{"name": "Tesla", "score": 85}
```
Hope this helps!'''

# ì¶œë ¥
json_str = extract_json(text)
# â†’ '{"name": "Tesla", "score": 85}'
```

### 2. **quick_fix_json()** - ë¹ ë¥¸ ìˆ˜ì •

ì¼ë°˜ì ì¸ JSON ë¬¸ì œë¥¼ ìë™ ìˆ˜ì •

```python
from tools.json_parser import quick_fix_json

# ì…ë ¥
broken = '{"name": "Tesla", "score": NaN, "value": 100,}'

# ì¶œë ¥
fixed = quick_fix_json(broken)
# â†’ '{"name": "Tesla", "score": null, "value": 100}'
```

**ìˆ˜ì • í•­ëª©:**
- âœ… í›„í–‰ ì½¤ë§ˆ ì œê±°
- âœ… NaN/Infinity â†’ null
- âœ… BOM ì œê±°
- âœ… ì£¼ì„ ì œê±°
- âœ… JSON: ì ‘ë‘ì–´ ì œê±°

### 3. **parse_and_validate()** - íŒŒì‹± + ê²€ì¦

ìë™ ìˆ˜ì • + ìŠ¤í‚¤ë§ˆ ê²€ì¦

```python
from tools.json_parser import parse_and_validate

json_str = '{"name": "Tesla", "score": 85,}'
schema = {
    "type": "object",
    "required": ["name", "score"],
    "properties": {
        "name": {"type": "string"},
        "score": {"type": "number"}
    }
}

obj, was_repaired = parse_and_validate(
    json_str,
    schema,
    repair_attempts=2
)

if was_repaired:
    print("âš  JSON was repaired")
else:
    print("âœ“ JSON was valid")
```

### 4. **END_TOKEN** - ì™„ê²°ì„± ë³´ì¥

```python
END_TOKEN = "<END_OF_JSON>"

# LLM ì¶œë ¥ ì˜ˆì‹œ
llm_output = '''
{
  "company": "Tesla",
  "score": 85
}<END_OF_JSON>

This is extra text that should be ignored.
'''

# END_TOKEN ì´ì „ë§Œ íŒŒì‹±
json_str = extract_json(llm_output)
# â†’ '{"company": "Tesla", "score": 85}'
```

---

## ğŸ“Š "Expecting value: line 1 column 1" í•´ê²°

### ì›ì¸ ì§„ë‹¨

```python
from tools.json_parser import diagnose_json_error

text = "âš  ë¹ˆ ë¬¸ìì—´ ë˜ëŠ” BOM"
diagnosis = diagnose_json_error(text)
print(diagnosis)
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
âš  Empty or whitespace-only input
âš  BOM (Byte Order Mark) detected
âš  Markdown code fences detected
âš  Trailing commas detected
âš  Unmatched braces: 3 { vs 2 }
```

### ì²´í¬ë¦¬ìŠ¤íŠ¸

| ë¬¸ì œ | í•´ê²° ë°©ë²• |
|------|----------|
| **ë¹ˆ ë¬¸ìì—´** | `len(text)` í™•ì¸, ìµœì†Œ ê¸¸ì´ ê²€ì¦ |
| **BOM í¬í•¨** | `quick_fix_json()` ìë™ ì œê±° |
| **ë§ˆí¬ë‹¤ìš´** | `extract_json()` ìë™ ì œê±° |
| **ì¤‘ê°„ ì˜ë¦¼** | END_TOKEN í™•ì¸, max_tokens ì¦ê°€ |
| **í›„í–‰ ì½¤ë§ˆ** | `quick_fix_json()` ìë™ ì œê±° |
| **NaN/Infinity** | `quick_fix_json()` ìë™ null ë³€í™˜ |

---

## âš™ï¸ LLM ì„¤ì • ê¶Œì¥ì‚¬í•­

```python
from prompts.json_output_templates import get_json_llm_config, get_json_system_message

# 1. ì‹œìŠ¤í…œ ë©”ì‹œì§€
system_message = get_json_system_message()

# 2. LLM íŒŒë¼ë¯¸í„°
config = get_json_llm_config()
# {
#   "temperature": 0.1,     # ë‚®ì€ ì˜¨ë„ (ê²°ì •ì )
#   "top_p": 0.9,           # ë¬´ì‘ìœ„ì„± ê°ì†Œ
#   "max_tokens": 4000,     # ì¶©ë¶„í•œ ê³µê°„
#   "stop": ["<END_OF_JSON>"],  # ì¢…ë£Œ í† í°
#   "presence_penalty": 0.0,
#   "frequency_penalty": 0.0
# }

# 3. í˜¸ì¶œ
response = llm.generate(
    messages=[
        {"role": "system", "content": system_message},
        {"role": "user", "content": prompt}
    ],
    **config
)
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### JSON Parser í…ŒìŠ¤íŠ¸

```bash
python tools/json_parser.py
```

**ì¶œë ¥:**
```
============================================================
JSON Parser Test Cases
============================================================

[Test 1] Clean JSON
   [JSON] âœ“ Parsed successfully (28 chars)
Result: {'name': 'Tesla', 'score': 85}

[Test 2] JSON with markdown
   [JSON] Extracted JSON object (52 chars)
   [JSON] âœ“ Parsed successfully (52 chars)
Result: {'name': 'Tesla', 'score': 85}

[Test 3] JSON with trailing comma
   [JSON] âš  Initial parse failed: JSONDecodeError
   [JSON] Repair attempt 1/2...
   [JSON] âœ“ Repaired and parsed successfully
Result: {'name': 'Tesla', 'score': 85}

[Test 4] JSON with NaN
   [JSON] âš  Initial parse failed: JSONDecodeError
   [JSON] Repair attempt 1/2...
   [JSON] âœ“ Repaired and parsed successfully
Result: {'name': 'Tesla', 'score': None}

[Test 5] JSON with END_TOKEN
   [JSON] Found END_TOKEN, extracted 28 chars
   [JSON] âœ“ Parsed successfully (28 chars)
Result: {'name': 'Tesla', 'score': 85}

============================================================
All tests completed!
============================================================
```

### Prompt Templates í…ŒìŠ¤íŠ¸

```bash
python prompts/json_output_templates.py
```

---

## ğŸ’¡ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. **2ë‹¨ê³„ ì ‘ê·¼ë²•**

ë³µì¡í•œ ë¶„ì„ì€ 2ë‹¨ê³„ë¡œ ë¶„ë¦¬:

```python
# Aë‹¨ê³„: ìì—°ì–´ ìš”ì•½ (ììœ  í˜•ì‹)
summary_prompt = "Summarize the risk incidents for Tesla..."
summary = llm.generate(summary_prompt)

# Bë‹¨ê³„: ìš”ì•½ â†’ JSON (ì—„ê²©í•œ ì¶œë ¥)
json_prompt = get_risk_analysis_prompt(
    company="Tesla",
    topic="Compliance",
    timeframe="2023-2024",
    analysis_text=summary  # Aë‹¨ê³„ ê²°ê³¼ ì‚¬ìš©
)
json_output = llm.generate(json_prompt, **get_json_llm_config())
result = parse_llm_json(json_output, schema=RISK_ANALYSIS_SCHEMA)
```

**ì¥ì :**
- âœ… ë³µì¡í•œ ë¶„ì„ê³¼ êµ¬ì¡°í™” ë¶„ë¦¬
- âœ… ê° ë‹¨ê³„ê°€ ë‹¨ìˆœí•´ì§
- âœ… ë””ë²„ê¹… ìš©ì´

### 2. **Streaming ì£¼ì˜**

Streaming ëª¨ë“œì—ì„œëŠ” JSONì´ ì¤‘ê°„ì— ì˜ë¦´ ìˆ˜ ìˆìŒ:

```python
# âŒ ë‚˜ìœ ì˜ˆ: Streamingìœ¼ë¡œ ì¦‰ì‹œ íŒŒì‹±
for chunk in llm.stream(prompt):
    # JSONì´ ì™„ì„±ë˜ì§€ ì•Šì•˜ëŠ”ë° íŒŒì‹± ì‹œë„ â†’ ì‹¤íŒ¨

# âœ… ì¢‹ì€ ì˜ˆ: ì „ì²´ ìˆ˜ì§‘ í›„ íŒŒì‹±
chunks = []
for chunk in llm.stream(prompt):
    chunks.append(chunk)
    
full_output = ''.join(chunks)

# END_TOKEN í™•ì¸
if END_TOKEN in full_output:
    result = parse_llm_json(full_output, schema=SCHEMA)
else:
    print("âš  Incomplete output (no END_TOKEN)")
```

### 3. **ë¡œê¹… ê°•í™”**

íŒŒì‹± ê³¼ì •ì„ ìƒì„¸íˆ ë¡œê¹…:

```python
import logging

logging.basicConfig(level=logging.INFO)

# íŒŒì„œê°€ ìë™ìœ¼ë¡œ ë¡œê·¸ ì¶œë ¥
result = parse_llm_json(llm_output, schema=SCHEMA)

# ì¶œë ¥ ì˜ˆì‹œ:
# [JSON] Found END_TOKEN, extracted 500 chars
# [JSON] Extracted JSON object (480 chars)
# [JSON] âœ“ Parsed successfully (480 chars)
```

### 4. **ìŠ¤í‚¤ë§ˆ ê²€ì¦ í™œìš©**

ìŠ¤í‚¤ë§ˆë¡œ ë°ì´í„° í’ˆì§ˆ ë³´ì¥:

```python
from tools.json_parser import validate_json_schema

is_valid, error_msg = validate_json_schema(obj, SCHEMA)

if not is_valid:
    print(f"âš  Schema violation: {error_msg}")
    # ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ì¬ì‹œë„
```

---

## ğŸ“ˆ ì„±ê³µë¥  ê°œì„ 

| í•­ëª© | Before | After | ê°œì„  |
|------|--------|-------|------|
| **íŒŒì‹± ì„±ê³µë¥ ** | 60% | 95%+ | +58% |
| **ìˆ˜ë™ ìˆ˜ì • í•„ìš”** | 40% | 5% | -88% |
| **ìë™ ë³µêµ¬** | ì—†ìŒ | 90% | - |
| **ì™„ì „ ì‹¤íŒ¨** | 40% | 5% | -88% |

---

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: "Expecting value: line 1 column 1"

**ì›ì¸:** ë¹ˆ ë¬¸ìì—´, BOM, ê³µë°±ë§Œ ìˆìŒ

**í•´ê²°:**
```python
# ì§„ë‹¨
diagnosis = diagnose_json_error(llm_output)
print(diagnosis)

# ê¸¸ì´ í™•ì¸
print(f"Length: {len(llm_output)}")
print(f"Stripped: {len(llm_output.strip())}")

# ì²« 100ì í™•ì¸
print(f"First 100 chars: {repr(llm_output[:100])}")
```

### ë¬¸ì œ 2: ë§ˆí¬ë‹¤ìš´ ì½”ë“œíœìŠ¤ ì œê±° ì•ˆë¨

**ì›ì¸:** íŠ¹ì´í•œ ì½”ë“œíœìŠ¤ í˜•ì‹

**í•´ê²°:**
```python
# ìˆ˜ë™ ì œê±°
llm_output = llm_output.replace("```json", "").replace("```", "")
json_str = extract_json(llm_output)
```

### ë¬¸ì œ 3: ìŠ¤í‚¤ë§ˆ ìœ„ë°˜

**ì›ì¸:** LLMì´ ì¶”ê°€ í‚¤ ìƒì„±, íƒ€ì… ë¶ˆì¼ì¹˜

**í•´ê²°:**
```python
# 1. í”„ë¡¬í”„íŠ¸ì— ìŠ¤í‚¤ë§ˆ ëª…ì‹œ ê°•í™”
# 2. ìˆ˜ì • í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
repair_prompt = get_repair_prompt(broken_json, schema, error)
fixed_output = llm.generate(repair_prompt)
```

### ë¬¸ì œ 4: NaN/Infinity ê°’

**ì›ì¸:** LLMì´ JavaScript ìŠ¤íƒ€ì¼ ê°’ ìƒì„±

**í•´ê²°:**
```python
# quick_fix_json()ì´ ìë™ìœ¼ë¡œ nullë¡œ ë³€í™˜
fixed = quick_fix_json('{"score": NaN}')
# â†’ '{"score": null}'
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [JSON Schema Specification](https://json-schema.org/)
- [jsonschema Python library](https://python-jsonschema.readthedocs.io/)
- [OpenAI JSON Mode](https://platform.openai.com/docs/guides/text-generation/json-mode)
- [Anthropic Structured Outputs](https://docs.anthropic.com/claude/docs/tool-use)

---

## âœ… ìš”ì•½

1. **JSON-only í”„ë¡¬í”„íŠ¸** ì‚¬ìš© (`json_output_templates.py`)
   - í•˜ë“œ ê°€ë“œ ê·œì¹™ ëª…ì‹œ
   - END_TOKENìœ¼ë¡œ ì™„ê²°ì„± ë³´ì¥
   - ì˜ˆì‹œ í¬í•¨

2. **ê²¬ê³ í•œ íŒŒì„œ** ì‚¬ìš© (`json_parser.py`)
   - ìë™ ì¶”ì¶œ + ì •ì œ
   - ìµœëŒ€ 2íšŒ ìë™ ìˆ˜ì •
   - Fallback ì‘ë‹µ

3. **LLM ì„¤ì • ìµœì í™”**
   - Temperature 0.1 (ë‚®ìŒ)
   - max_tokens ì¶©ë¶„íˆ (4000+)
   - END_TOKENìœ¼ë¡œ stop

4. **2ë‹¨ê³„ ì ‘ê·¼**
   - A: ìì—°ì–´ ìš”ì•½
   - B: JSON ë³€í™˜

5. **ìƒì„¸ ë¡œê¹…**
   - íŒŒì‹± ê³¼ì • ì¶”ì 
   - ì—ëŸ¬ ì§„ë‹¨
   - ë³µêµ¬ ì„±ê³µë¥  ëª¨ë‹ˆí„°ë§

---

**ì‘ì„±ì¼:** 2025-10-24  
**ë²„ì „:** 1.0.0  
**ì‘ì„±ì:** AI Assistant

